# ğŸ—ï¸ Architecture

Deep dive into Ratatouille's technical architecture.

---

## Overview

Ratatouille follows a **Medallion Lakehouse Architecture** with three data layers:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           DATA LAKEHOUSE                                â”‚
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚   â”‚   BRONZE    â”‚      â”‚   SILVER    â”‚      â”‚    GOLD     â”‚            â”‚
â”‚   â”‚  (Raw Data) â”‚ â”€â”€â”€â–¶ â”‚  (Cleaned)  â”‚ â”€â”€â”€â–¶ â”‚ (Business)  â”‚            â”‚
â”‚   â”‚             â”‚      â”‚             â”‚      â”‚             â”‚            â”‚
â”‚   â”‚ â€¢ Immutable â”‚      â”‚ â€¢ Validated â”‚      â”‚ â€¢ Aggregatedâ”‚            â”‚
â”‚   â”‚ â€¢ As-is     â”‚      â”‚ â€¢ Dedupe'd  â”‚      â”‚ â€¢ KPIs      â”‚            â”‚
â”‚   â”‚ â€¢ All data  â”‚      â”‚ â€¢ Typed     â”‚      â”‚ â€¢ Joined    â”‚            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                    â”‚                    â”‚                     â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                              â”‚                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                    â”‚  Apache Iceberg   â”‚                               â”‚
â”‚                    â”‚   (Table Format)  â”‚                               â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                              â”‚                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                    â”‚      MinIO        â”‚                               â”‚
â”‚                    â”‚ (S3-Compatible)   â”‚                               â”‚
â”‚                    â”‚  Parquet Files    â”‚                               â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Components

### 1. MinIO (Object Storage)

**Role:** S3-compatible object storage for all data files.

```
s3://
â”œâ”€â”€ landing/          # Raw incoming files (Excel, CSV, etc.)
â”œâ”€â”€ bronze/           # (Reserved for future use)
â”œâ”€â”€ silver/           # (Reserved for future use)
â”œâ”€â”€ gold/             # (Reserved for future use)
â””â”€â”€ warehouse/        # Iceberg table data (Parquet files)
    â”œâ”€â”€ bronze/
    â”‚   â””â”€â”€ table_name/
    â”‚       â”œâ”€â”€ metadata/
    â”‚       â””â”€â”€ data/*.parquet
    â”œâ”€â”€ silver/
    â””â”€â”€ gold/
```

**Configuration:**
```yaml
# docker-compose.yml
minio:
  image: minio/minio:latest
  ports:
    - "9000:9000"   # S3 API
    - "9001:9001"   # Web Console
  environment:
    MINIO_ROOT_USER: ratatouille
    MINIO_ROOT_PASSWORD: ratatouille123
```

---

### 2. Apache Iceberg (Table Format)

**Role:** Table format providing ACID transactions, time travel, and schema evolution.

**Why Iceberg over raw Parquet?**
- âœ… **ACID transactions** - No partial writes
- âœ… **Time travel** - Query historical data
- âœ… **Schema evolution** - Add/rename columns safely
- âœ… **Partition evolution** - Change partitioning without rewriting
- âœ… **Hidden partitioning** - No partition columns in queries

**Catalog:** SQLite-based catalog (no external service needed)

```python
# Iceberg catalog configuration
catalog = SqlCatalog(
    "ratatouille",
    uri="sqlite:////app/workspaces/.iceberg/catalog.db",
    warehouse="s3://warehouse/",
    s3.endpoint="http://minio:9000",
)
```

**Table Structure:**
```
s3://warehouse/bronze/sales/
â”œâ”€â”€ metadata/
â”‚   â”œâ”€â”€ v1.metadata.json
â”‚   â”œâ”€â”€ v2.metadata.json      # Schema/partition changes
â”‚   â””â”€â”€ snap-123456.avro      # Snapshot manifest
â””â”€â”€ data/
    â”œâ”€â”€ 00001-abc.parquet
    â”œâ”€â”€ 00002-def.parquet     # Data files
    â””â”€â”€ 00003-ghi.parquet
```

---

### 3. ClickHouse (Query Engine)

**Role:** Fast OLAP analytics engine for querying lakehouse data.

**Why ClickHouse?**
- âš¡ **Sub-second queries** on millions of rows
- ğŸ“Š **Native BI support** - ODBC/JDBC for Power BI, Tableau
- ğŸ”— **S3 integration** - Query Parquet files directly
- ğŸ’¾ **Optional materialization** - Create tables for ultra-fast access

**Query Patterns:**

```sql
-- Direct S3 query (federated)
SELECT * FROM s3(
    'http://minio:9000/warehouse/bronze/sales/data/*.parquet',
    'ratatouille', 'ratatouille123', 'Parquet'
)

-- Materialized table (faster, but needs refresh)
CREATE TABLE gold_sales
ENGINE = MergeTree()
ORDER BY date
AS SELECT * FROM s3(...)
```

**Configuration:**
```yaml
# docker-compose.yml
clickhouse:
  image: clickhouse/clickhouse-server:latest
  ports:
    - "8123:8123"   # HTTP API (Power BI, REST)
    - "9440:9000"   # Native protocol
```

---

### 4. Dagster (Orchestration)

**Role:** Pipeline orchestration, scheduling, and monitoring.

**Key Concepts:**

| Concept | Description |
|---------|-------------|
| **Asset** | A data artifact (table, file, model) |
| **Job** | A selection of assets to run together |
| **Sensor** | Triggers jobs based on events (new files, time) |
| **Asset Check** | Data quality validation |

**Asset Example:**
```python
@asset(
    group_name="my_parser",
    deps=[my_bronze],          # Dependency
    compute_kind="sql",         # Icon in UI
)
def my_silver(context):
    result = rat.transform(...)
    return MaterializeResult(metadata={...})
```

**File Structure:**
```
pipelines/
â”œâ”€â”€ __init__.py           # Exports all_assets, all_sensors, etc.
â””â”€â”€ example/
    â”œâ”€â”€ __init__.py       # Exports my_bronze, my_silver
    â”œâ”€â”€ assets.py         # Asset definitions
    â””â”€â”€ checks.py         # Quality checks
```

---

### 5. Jupyter Lab (Development)

**Role:** Interactive development environment with LSP and linting.

**Features:**
- ğŸ”§ **Language Server Protocol (LSP)** - Autocomplete, go-to-definition
- ğŸ“ **Ruff Linting** - Fast Python linting
- ğŸ“ **Workspace mount** - Edit files that persist

**Access:**
- URL: http://localhost:8889
- Token: `ratatouille`
- Notebook directory: `/app/workspaces`

---

## Data Flow

### Ingestion Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Source File  â”‚     â”‚   Parser     â”‚     â”‚   Iceberg    â”‚
â”‚  (Excel/CSV) â”‚ â”€â”€â–¶ â”‚ (Transform)  â”‚ â”€â”€â–¶ â”‚   (Bronze)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚                    â”‚
       â”‚    rat.ice_ingest("landing/...",       â”‚
       â”‚        "bronze.table", parser=my_parser)   â”‚
       â”‚                                         â”‚
       â–¼                                         â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ MinIO     â”‚                          â”‚ File Trackingâ”‚
 â”‚ landing/  â”‚                          â”‚ (Registry)   â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Transform Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Bronze     â”‚     â”‚  ClickHouse  â”‚     â”‚   Silver     â”‚
â”‚  (Iceberg)   â”‚ â”€â”€â–¶ â”‚  (SQL Query) â”‚ â”€â”€â–¶ â”‚  (Iceberg)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚                    â”‚
       â”‚    rat.transform(                       â”‚
       â”‚        sql="SELECT ... FROM {bronze.x}",â”‚
       â”‚        target="silver.y",               â”‚
       â”‚        merge_keys=[...])                â”‚
       â”‚                                         â”‚
       â–¼                                         â–¼
   Read via                              Write via
   s3() function                         PyIceberg
```

---

## Service Communication

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Docker Network                           â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   Jupyter   â”‚ â”€â”€â”€â”€â”€â”€â–¶ â”‚  ClickHouse â”‚                   â”‚
â”‚  â”‚  :8888      â”‚         â”‚   :8123     â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â”‚                       â”‚                           â”‚
â”‚         â”‚ S3 API                â”‚ S3 API                    â”‚
â”‚         â–¼                       â–¼                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚              MinIO                   â”‚                   â”‚
â”‚  â”‚              :9000                   â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â–²                                                   â”‚
â”‚         â”‚                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚   Dagster   â”‚                                           â”‚
â”‚  â”‚   :3000     â”‚                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚              â”‚              â”‚
         â–¼              â–¼              â–¼              â–¼
    localhost:     localhost:     localhost:     localhost:
       8889           8123           3030         9000/9001
     (Jupyter)    (ClickHouse)    (Dagster)       (MinIO)
```

**Internal hostnames:**
- `minio:9000` - MinIO S3 API
- `clickhouse:8123` - ClickHouse HTTP
- Services discover each other by container name

---

## Workspace Auto-Discovery

Pipelines in `workspaces/*/pipelines/*.py` are automatically loaded:

```python
# ratatouille/discovery.py

def discover_workspace_assets():
    # Scan: workspaces/*/pipelines/*.py
    for file in glob("workspaces/*/pipelines/*.py"):
        module = load_module(file)
        for obj in dir(module):
            if isinstance(obj, AssetsDefinition):
                yield obj
```

**Conventions:**
1. Place `.py` files in `workspaces/<name>/pipelines/`
2. Use `@asset` decorator from Dagster
3. Dagster auto-discovers on startup

---

## File Tracking (Production)

For production ingestion, file tracking prevents re-processing:

```python
# Enable tracking
df, stats = rat.ice_ingest_batch(
    "landing/sales/",
    "bronze.sales",
    skip_existing=True  # â† Check registry before ingesting
)
```

**Registry table:** `bronze._file_registry`

| Column | Description |
|--------|-------------|
| `file_path` | S3 path of ingested file |
| `file_hash` | MD5 hash of file contents |
| `target_table` | Destination Iceberg table |
| `rows_ingested` | Number of rows written |
| `ingested_at` | Timestamp |
| `status` | success / failed / skipped |

---

## Security Considerations

âš ï¸ **Default credentials are for development only!**

| Service | Default User | Default Password |
|---------|--------------|------------------|
| MinIO | `ratatouille` | `ratatouille123` |
| ClickHouse | `ratatouille` | `ratatouille123` |
| Jupyter | - | Token: `ratatouille` |

For production:
1. Change all passwords in `docker-compose.yml`
2. Use secrets management (Docker secrets, Vault)
3. Enable TLS/HTTPS
4. Restrict network access

---

## Scaling Considerations

### Current: Single Node

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Your Machine             â”‚
â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ MinIO  â”‚ â”‚ Click  â”‚ â”‚Dagsterâ”‚â”‚
â”‚  â”‚        â”‚ â”‚ House  â”‚ â”‚       â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Future: Kubernetes (K3s)

Same container specs work with K3s/Kubernetes:

```yaml
# Convert docker-compose.yml â†’ k8s manifests
# Podman pod specs are K8s-compatible!

apiVersion: apps/v1
kind: Deployment
metadata:
  name: ratatouille-clickhouse
spec:
  replicas: 1  # Scale to 3 for HA
  ...
```

**Scale-out path:**
1. MinIO â†’ MinIO Cluster (or real S3)
2. ClickHouse â†’ ClickHouse Cluster
3. Dagster â†’ Dagster Cloud or K8s deployment
